{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94ff364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=57180aa7c28ebcc6735a1c9a6aa5c273a15338ce2c7aaf704dfc11a651354809\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71520508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome to Wikipedia',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries and python package \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "# Sending request to the webpage server to get the source code \n",
    "page=requests.get('https://en.wikipedia.org/wiki/Main_Page','https://www.imdb.com/search/title/?groups=top_100&view=simple&sort=moviemeter,desc&start=51&ref_=adv_nxt')\n",
    "page\n",
    "#Getting the content from the page \n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "# Scrapping the first header tag \n",
    "\n",
    "first_title=soup.find('span',class_='mw-headline')\n",
    "first_title\n",
    "first_title.text\n",
    "# Scrapping all the headers \n",
    "\n",
    "title=[]\n",
    "for i in soup.find_all('span',class_='mw-headline'):\n",
    "    title.append(i.text)\n",
    "title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b567444f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1963)',\n",
       " '(1931)',\n",
       " '(1936)',\n",
       " '(1957)',\n",
       " '(1940)',\n",
       " '(1931)',\n",
       " '(1962)',\n",
       " '(1957)',\n",
       " '(1950)',\n",
       " '(1952)',\n",
       " '(1954)',\n",
       " '(1988)',\n",
       " '(1958)',\n",
       " '(2010)',\n",
       " '(1941)',\n",
       " '(1981)',\n",
       " '(1954)',\n",
       " '(1997)',\n",
       " '(1964)',\n",
       " '(1988)',\n",
       " '(1962)',\n",
       " '(2018)',\n",
       " '(2006)',\n",
       " '(2009)',\n",
       " '(1983)',\n",
       " '(2016)',\n",
       " '(2008)',\n",
       " '(1960)',\n",
       " '(1980)',\n",
       " '(1995)',\n",
       " '(1984)',\n",
       " '(I) (2017)',\n",
       " '(1998)',\n",
       " '(2002)',\n",
       " '(1942)',\n",
       " '(2011)',\n",
       " '(1968)',\n",
       " '(1997)',\n",
       " '(1968)',\n",
       " '(1966)',\n",
       " '(2002)',\n",
       " '(2002)',\n",
       " '(2012)',\n",
       " '(1991)',\n",
       " '(2000)',\n",
       " '(2003)',\n",
       " '(1995)',\n",
       " '(1959)',\n",
       " '(1975)',\n",
       " '(2001)']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending request to the webpage server to get the source code \n",
    "page=requests.get('https://www.imdb.com/search/title/?groups=top_100&view=simple&sort=moviemeter,desc&ref_=adv_prv')\n",
    "page\n",
    "#Getting the content from the page \n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "# scrapping the names of the movie\n",
    "name=[]\n",
    "for i in soup.find_all('span',class_='lister-item-header'):\n",
    "    name.append(i.text.split('|')[0])\n",
    "name\n",
    "# scrapping the ratings of all the movies \n",
    "ratings=[]\n",
    "for i in soup.find_all('div',class_='col-imdb-rating'):\n",
    "    ratings.append(i.text)\n",
    "ratings\n",
    "# scrapping the yaer of movie releases\n",
    "year=[]\n",
    "for i in soup.find_all('span',class_='lister-item-year text-muted unbold'):\n",
    "    year.append(i.text)\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2072e0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Release year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n1.\\n\\nTengoku to jigoku\\n(1963)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(1963)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n2.\\n\\nCity Lights\\n(1931)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.5\\n         ...</td>\n",
       "      <td>(1931)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n3.\\n\\nModern Times\\n(1936)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.5\\n         ...</td>\n",
       "      <td>(1936)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n4.\\n\\nWitness for the Prosecution\\n(1957)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n5.\\n\\nThe Great Dictator\\n(1940)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(1940)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n6.\\n\\nM - Eine Stadt sucht einen MÃ¶rder\\n(19...</td>\n",
       "      <td>\\n\\n                            8.3\\n         ...</td>\n",
       "      <td>(1931)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n7.\\n\\nSeppuku\\n(1962)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.6\\n         ...</td>\n",
       "      <td>(1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n8.\\n\\nPaths of Glory\\n(1957)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n9.\\n\\nSunset Blvd.\\n(1950)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(1950)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n10.\\n\\nSingin' in the Rain\\n(1952)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.3\\n         ...</td>\n",
       "      <td>(1952)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\n11.\\n\\nRear Window\\n(1954)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.5\\n         ...</td>\n",
       "      <td>(1954)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\n12.\\n\\nNuovo Cinema Paradiso\\n(1988)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.5\\n         ...</td>\n",
       "      <td>(1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\n13.\\n\\nVertigo\\n(1958)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.3\\n         ...</td>\n",
       "      <td>(1958)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\n14.\\n\\nToy Story 3\\n(2010)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.3\\n         ...</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\n15.\\n\\nCitizen Kane\\n(1941)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.3\\n         ...</td>\n",
       "      <td>(1941)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\n16.\\n\\nDas Boot\\n(1981)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(1981)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\\n17.\\n\\nShichinin no samurai\\n(1954)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.6\\n         ...</td>\n",
       "      <td>(1954)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\n18.\\n\\nMononoke-hime\\n(1997)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\n19.\\n\\nDr. Strangelove or: How I Learned to ...</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(1964)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\n20.\\n\\nHotaru no haka\\n(1988)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.5\\n         ...</td>\n",
       "      <td>(1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\n21.\\n\\nLawrence of Arabia\\n(1962)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.3\\n         ...</td>\n",
       "      <td>(1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\n22.\\n\\nCapharnaÃ¼m\\n(2018)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\\n23.\\n\\nThe Lives of Others\\n(2006)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\\n24.\\n\\n3 Idiots\\n(2009)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\\n25.\\n\\nStar Wars: Episode VI - Return of the...</td>\n",
       "      <td>\\n\\n                            8.3\\n         ...</td>\n",
       "      <td>(1983)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\\n26.\\n\\nKimi no Na wa.\\n(2016)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(2016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\\n27.\\n\\nWALLÂ·E\\n(2008)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\\n28.\\n\\nPsycho\\n(1960)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.5\\n         ...</td>\n",
       "      <td>(1960)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\\n29.\\n\\nThe Empire Strikes Back\\n(1980)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.7\\n         ...</td>\n",
       "      <td>(1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\\n30.\\n\\nToy Story\\n(1995)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.3\\n         ...</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\\n31.\\n\\nAmadeus\\n(1984)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(1984)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\\n32.\\n\\nCoco\\n(I) (2017)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(I) (2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\\n33.\\n\\nAmerican History X\\n(1998)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.5\\n         ...</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\\n34.\\n\\nThe Pianist\\n(2002)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.5\\n         ...</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>\\n35.\\n\\nCasablanca\\n(1942)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.5\\n         ...</td>\n",
       "      <td>(1942)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>\\n36.\\n\\nThe Intouchables\\n(2011)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.5\\n         ...</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>\\n37.\\n\\n2001: A Space Odyssey\\n(1968)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.3\\n         ...</td>\n",
       "      <td>(1968)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>\\n38.\\n\\nLa vita Ã¨ bella\\n(1997)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.6\\n         ...</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\\n39.\\n\\nOnce Upon a Time in the West\\n(1968)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.5\\n         ...</td>\n",
       "      <td>(1968)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\\n40.\\n\\nIl buono, il brutto, il cattivo\\n(196...</td>\n",
       "      <td>\\n\\n                            8.8\\n         ...</td>\n",
       "      <td>(1966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>\\n41.\\n\\nCidade de Deus\\n(2002)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.6\\n         ...</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>\\n42.\\n\\nThe Lord of the Rings: The Two Towers...</td>\n",
       "      <td>\\n\\n                            8.8\\n         ...</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>\\n43.\\n\\nJagten\\n(2012)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.3\\n         ...</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>\\n44.\\n\\nTerminator 2: Judgment Day\\n(1991)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.6\\n         ...</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>\\n45.\\n\\nMemento\\n(2000)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>\\n46.\\n\\nOldeuboi\\n(2003)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>\\n47.\\n\\nBraveheart\\n(1995)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.4\\n         ...</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>\\n48.\\n\\nNorth by Northwest\\n(1959)\\n\\n</td>\n",
       "      <td>\\n\\n                            8.3\\n         ...</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>\\n49.\\n\\nOne Flew Over the Cuckoo's Nest\\n(197...</td>\n",
       "      <td>\\n\\n                            8.7\\n         ...</td>\n",
       "      <td>(1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>\\n50.\\n\\nSen to Chihiro no kamikakushi\\n(2001)...</td>\n",
       "      <td>\\n\\n                            8.6\\n         ...</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Movie name  \\\n",
       "0               \\n1.\\n\\nTengoku to jigoku\\n(1963)\\n\\n   \n",
       "1                     \\n2.\\n\\nCity Lights\\n(1931)\\n\\n   \n",
       "2                    \\n3.\\n\\nModern Times\\n(1936)\\n\\n   \n",
       "3     \\n4.\\n\\nWitness for the Prosecution\\n(1957)\\n\\n   \n",
       "4              \\n5.\\n\\nThe Great Dictator\\n(1940)\\n\\n   \n",
       "5   \\n6.\\n\\nM - Eine Stadt sucht einen MÃ¶rder\\n(19...   \n",
       "6                         \\n7.\\n\\nSeppuku\\n(1962)\\n\\n   \n",
       "7                  \\n8.\\n\\nPaths of Glory\\n(1957)\\n\\n   \n",
       "8                    \\n9.\\n\\nSunset Blvd.\\n(1950)\\n\\n   \n",
       "9            \\n10.\\n\\nSingin' in the Rain\\n(1952)\\n\\n   \n",
       "10                   \\n11.\\n\\nRear Window\\n(1954)\\n\\n   \n",
       "11         \\n12.\\n\\nNuovo Cinema Paradiso\\n(1988)\\n\\n   \n",
       "12                       \\n13.\\n\\nVertigo\\n(1958)\\n\\n   \n",
       "13                   \\n14.\\n\\nToy Story 3\\n(2010)\\n\\n   \n",
       "14                  \\n15.\\n\\nCitizen Kane\\n(1941)\\n\\n   \n",
       "15                      \\n16.\\n\\nDas Boot\\n(1981)\\n\\n   \n",
       "16          \\n17.\\n\\nShichinin no samurai\\n(1954)\\n\\n   \n",
       "17                 \\n18.\\n\\nMononoke-hime\\n(1997)\\n\\n   \n",
       "18  \\n19.\\n\\nDr. Strangelove or: How I Learned to ...   \n",
       "19                \\n20.\\n\\nHotaru no haka\\n(1988)\\n\\n   \n",
       "20            \\n21.\\n\\nLawrence of Arabia\\n(1962)\\n\\n   \n",
       "21                    \\n22.\\n\\nCapharnaÃ¼m\\n(2018)\\n\\n   \n",
       "22           \\n23.\\n\\nThe Lives of Others\\n(2006)\\n\\n   \n",
       "23                      \\n24.\\n\\n3 Idiots\\n(2009)\\n\\n   \n",
       "24  \\n25.\\n\\nStar Wars: Episode VI - Return of the...   \n",
       "25                \\n26.\\n\\nKimi no Na wa.\\n(2016)\\n\\n   \n",
       "26                        \\n27.\\n\\nWALLÂ·E\\n(2008)\\n\\n   \n",
       "27                        \\n28.\\n\\nPsycho\\n(1960)\\n\\n   \n",
       "28       \\n29.\\n\\nThe Empire Strikes Back\\n(1980)\\n\\n   \n",
       "29                     \\n30.\\n\\nToy Story\\n(1995)\\n\\n   \n",
       "30                       \\n31.\\n\\nAmadeus\\n(1984)\\n\\n   \n",
       "31                      \\n32.\\n\\nCoco\\n(I) (2017)\\n\\n   \n",
       "32            \\n33.\\n\\nAmerican History X\\n(1998)\\n\\n   \n",
       "33                   \\n34.\\n\\nThe Pianist\\n(2002)\\n\\n   \n",
       "34                    \\n35.\\n\\nCasablanca\\n(1942)\\n\\n   \n",
       "35              \\n36.\\n\\nThe Intouchables\\n(2011)\\n\\n   \n",
       "36         \\n37.\\n\\n2001: A Space Odyssey\\n(1968)\\n\\n   \n",
       "37               \\n38.\\n\\nLa vita Ã¨ bella\\n(1997)\\n\\n   \n",
       "38  \\n39.\\n\\nOnce Upon a Time in the West\\n(1968)\\n\\n   \n",
       "39  \\n40.\\n\\nIl buono, il brutto, il cattivo\\n(196...   \n",
       "40                \\n41.\\n\\nCidade de Deus\\n(2002)\\n\\n   \n",
       "41  \\n42.\\n\\nThe Lord of the Rings: The Two Towers...   \n",
       "42                        \\n43.\\n\\nJagten\\n(2012)\\n\\n   \n",
       "43    \\n44.\\n\\nTerminator 2: Judgment Day\\n(1991)\\n\\n   \n",
       "44                       \\n45.\\n\\nMemento\\n(2000)\\n\\n   \n",
       "45                      \\n46.\\n\\nOldeuboi\\n(2003)\\n\\n   \n",
       "46                    \\n47.\\n\\nBraveheart\\n(1995)\\n\\n   \n",
       "47            \\n48.\\n\\nNorth by Northwest\\n(1959)\\n\\n   \n",
       "48  \\n49.\\n\\nOne Flew Over the Cuckoo's Nest\\n(197...   \n",
       "49  \\n50.\\n\\nSen to Chihiro no kamikakushi\\n(2001)...   \n",
       "\n",
       "                                              Ratings Release year  \n",
       "0   \\n\\n                            8.4\\n         ...       (1963)  \n",
       "1   \\n\\n                            8.5\\n         ...       (1931)  \n",
       "2   \\n\\n                            8.5\\n         ...       (1936)  \n",
       "3   \\n\\n                            8.4\\n         ...       (1957)  \n",
       "4   \\n\\n                            8.4\\n         ...       (1940)  \n",
       "5   \\n\\n                            8.3\\n         ...       (1931)  \n",
       "6   \\n\\n                            8.6\\n         ...       (1962)  \n",
       "7   \\n\\n                            8.4\\n         ...       (1957)  \n",
       "8   \\n\\n                            8.4\\n         ...       (1950)  \n",
       "9   \\n\\n                            8.3\\n         ...       (1952)  \n",
       "10  \\n\\n                            8.5\\n         ...       (1954)  \n",
       "11  \\n\\n                            8.5\\n         ...       (1988)  \n",
       "12  \\n\\n                            8.3\\n         ...       (1958)  \n",
       "13  \\n\\n                            8.3\\n         ...       (2010)  \n",
       "14  \\n\\n                            8.3\\n         ...       (1941)  \n",
       "15  \\n\\n                            8.4\\n         ...       (1981)  \n",
       "16  \\n\\n                            8.6\\n         ...       (1954)  \n",
       "17  \\n\\n                            8.4\\n         ...       (1997)  \n",
       "18  \\n\\n                            8.4\\n         ...       (1964)  \n",
       "19  \\n\\n                            8.5\\n         ...       (1988)  \n",
       "20  \\n\\n                            8.3\\n         ...       (1962)  \n",
       "21  \\n\\n                            8.4\\n         ...       (2018)  \n",
       "22  \\n\\n                            8.4\\n         ...       (2006)  \n",
       "23  \\n\\n                            8.4\\n         ...       (2009)  \n",
       "24  \\n\\n                            8.3\\n         ...       (1983)  \n",
       "25  \\n\\n                            8.4\\n         ...       (2016)  \n",
       "26  \\n\\n                            8.4\\n         ...       (2008)  \n",
       "27  \\n\\n                            8.5\\n         ...       (1960)  \n",
       "28  \\n\\n                            8.7\\n         ...       (1980)  \n",
       "29  \\n\\n                            8.3\\n         ...       (1995)  \n",
       "30  \\n\\n                            8.4\\n         ...       (1984)  \n",
       "31  \\n\\n                            8.4\\n         ...   (I) (2017)  \n",
       "32  \\n\\n                            8.5\\n         ...       (1998)  \n",
       "33  \\n\\n                            8.5\\n         ...       (2002)  \n",
       "34  \\n\\n                            8.5\\n         ...       (1942)  \n",
       "35  \\n\\n                            8.5\\n         ...       (2011)  \n",
       "36  \\n\\n                            8.3\\n         ...       (1968)  \n",
       "37  \\n\\n                            8.6\\n         ...       (1997)  \n",
       "38  \\n\\n                            8.5\\n         ...       (1968)  \n",
       "39  \\n\\n                            8.8\\n         ...       (1966)  \n",
       "40  \\n\\n                            8.6\\n         ...       (2002)  \n",
       "41  \\n\\n                            8.8\\n         ...       (2002)  \n",
       "42  \\n\\n                            8.3\\n         ...       (2012)  \n",
       "43  \\n\\n                            8.6\\n         ...       (1991)  \n",
       "44  \\n\\n                            8.4\\n         ...       (2000)  \n",
       "45  \\n\\n                            8.4\\n         ...       (2003)  \n",
       "46  \\n\\n                            8.4\\n         ...       (1995)  \n",
       "47  \\n\\n                            8.3\\n         ...       (1959)  \n",
       "48  \\n\\n                            8.7\\n         ...       (1975)  \n",
       "49  \\n\\n                            8.6\\n         ...       (2001)  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the lengths\n",
    "print(len(name),len(ratings),len(year))\n",
    "\n",
    "# making the dataframe \n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Movie name':name,'Ratings':ratings,'Release year':year})\n",
    "df                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4afd38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 250 250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Release year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n      1.\\n      Ramayana: The Legend of Prin...</td>\n",
       "      <td>\\n8.5\\n</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n      2.\\n      Rocketry: The Nambi Effect\\n...</td>\n",
       "      <td>\\n8.4\\n</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n      3.\\n      Golmaal\\n(1979)\\n</td>\n",
       "      <td>\\n8.4\\n</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n      4.\\n      777 Charlie\\n(2022)\\n</td>\n",
       "      <td>\\n8.4\\n</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n      5.\\n      Nayakan\\n(1987)\\n</td>\n",
       "      <td>\\n8.4\\n</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>\\n      96.\\n      Kaakkaa Muttai\\n(2014)\\n</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>\\n      97.\\n      Ustad Hotel\\n(2012)\\n</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>\\n      98.\\n      Theeran Adhigaaram Ondru\\n(...</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>\\n      99.\\n      Angoor\\n(1982)\\n</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "      <td>(1982)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>\\n      100.\\n      Rang De Basanti\\n(2006)\\n</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Movie name  Ratings Release year\n",
       "0   \\n      1.\\n      Ramayana: The Legend of Prin...  \\n8.5\\n       (1993)\n",
       "1   \\n      2.\\n      Rocketry: The Nambi Effect\\n...  \\n8.4\\n       (2022)\n",
       "2                 \\n      3.\\n      Golmaal\\n(1979)\\n  \\n8.4\\n       (1979)\n",
       "3             \\n      4.\\n      777 Charlie\\n(2022)\\n  \\n8.4\\n       (2022)\n",
       "4                 \\n      5.\\n      Nayakan\\n(1987)\\n  \\n8.4\\n       (1987)\n",
       "..                                                ...      ...          ...\n",
       "95        \\n      96.\\n      Kaakkaa Muttai\\n(2014)\\n  \\n8.0\\n       (2014)\n",
       "96           \\n      97.\\n      Ustad Hotel\\n(2012)\\n  \\n8.0\\n       (2012)\n",
       "97  \\n      98.\\n      Theeran Adhigaaram Ondru\\n(...  \\n8.0\\n       (2017)\n",
       "98                \\n      99.\\n      Angoor\\n(1982)\\n  \\n8.0\\n       (1982)\n",
       "99      \\n      100.\\n      Rang De Basanti\\n(2006)\\n  \\n8.0\\n       (2006)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending request to the webpage server to get the source code \n",
    "page=requests.get('https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=461131e5-5af0-4e50-bee2-223fad1e00ca&pf_rd_r=7FBBWAAGJAQSPCMAVYEJ&pf_rd_s=center-1&pf_rd_t=60601&pf_rd_i=india.toprated&ref_=fea_india_ss_toprated_india_tr_india250_hd')\n",
    "page\n",
    "#Getting the content from the page \n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "# scrapping the names of the movie\n",
    "name=[]\n",
    "for i in soup.find_all('td',class_='titleColumn'):\n",
    "    name.append(i.text)\n",
    "name[0:100]\n",
    "# scrapping the ratings of all the movies \n",
    "ratings=[]\n",
    "for i in soup.find_all('td',class_='ratingColumn imdbRating'):\n",
    "    ratings.append(i.text)\n",
    "ratings[0:100]\n",
    "# scrapping the yaer of movie releases\n",
    "year=[]\n",
    "for i in soup.find_all('span',class_='secondaryInfo'):\n",
    "    year.append(i.text)\n",
    "year[0:100]\n",
    "#printing the lengths\n",
    "print(len(name),len(ratings),len(year))\n",
    "\n",
    "# making the dataframe \n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Movie name':name,'Ratings':ratings,'Release year':year})\n",
    "df.head(100)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05369cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['',\n",
       "  'Shri Ram Nath Kovind (birth - 1945)',\n",
       "  'Term of Office: 25 July, 2017 to 25 July, 2022 '],\n",
       " ['',\n",
       "  'Shri Pranab Mukherjee (1935-2020)',\n",
       "  'Term of Office: 25 July, 2012 to 25 July, 2017 '],\n",
       " ['',\n",
       "  'Smt Pratibha Devisingh Patil (birth - 1934)',\n",
       "  'Term of Office: 25 July, 2007 to 25 July, 2012 '],\n",
       " ['',\n",
       "  'DR. A.P.J. Abdul Kalam (1931-2015)',\n",
       "  'Term of Office: 25 July, 2002 to 25 July, 2007 '],\n",
       " ['',\n",
       "  'Shri K. R. Narayanan (1920 - 2005)',\n",
       "  'Term of Office: 25 July, 1997 to 25 July, 2002 '],\n",
       " ['',\n",
       "  'Dr Shankar Dayal Sharma (1918-1999)',\n",
       "  'Term of Office: 25 July, 1992 to 25 July, 1997 '],\n",
       " ['',\n",
       "  'Shri R Venkataraman (1910-2009)',\n",
       "  'Term of Office: 25 July, 1987 to 25 July, 1992 '],\n",
       " ['',\n",
       "  'Giani Zail Singh (1916-1994)',\n",
       "  'Term of Office: 25 July, 1982 to 25 July, 1987 '],\n",
       " ['',\n",
       "  'Shri Neelam Sanjiva Reddy (1913-1996)',\n",
       "  'Term of Office: 25 July, 1977 to 25 July, 1982 '],\n",
       " ['',\n",
       "  'Dr. Fakhruddin Ali Ahmed (1905-1977)',\n",
       "  'Term of Office: 24 August, 1974 to 11 February, 1977'],\n",
       " ['',\n",
       "  'Shri Varahagiri Venkata Giri (1894-1980)',\n",
       "  'Term of Office: 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974'],\n",
       " ['',\n",
       "  'Dr. Zakir Husain (1897-1969)',\n",
       "  'Term of Office: 13 May, 1967 to 3 May, 1969'],\n",
       " ['',\n",
       "  'Dr. Sarvepalli Radhakrishnan (1888-1975)',\n",
       "  'Term of Office: 13 May, 1962 to 13 May, 1967'],\n",
       " ['',\n",
       "  'Dr. Rajendra Prasad (1884-1963) ',\n",
       "  'Term of Office: 26 January, 1950 to 13 May, 1962']]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending request to the webpage server to get the source code \n",
    "page=requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "page\n",
    "#Getting the content from the page \n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "# Scrapping the former presidents names with their term of office\n",
    "president=[]\n",
    "for i in soup.find_all('div',class_='presidentListing'):\n",
    "    president.append(i.text.split('\\n')[0:3])\n",
    "president"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20c93ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['England', 'ENG', '', '30', '3,400', '113'],\n",
       " ['Australia', 'AUS', '', '32', '3,572', '112'],\n",
       " ['India', 'IND', '', '35', '3,866', '110'],\n",
       " ['Pakistan', 'PAK', '', '22', '2,354', '107'],\n",
       " ['South Africa', 'SA', '', '24', '2,392', '100'],\n",
       " ['Bangladesh', 'BAN', '', '30', '2,753', '92'],\n",
       " ['Sri Lanka', 'SL', '', '30', '2,677', '89'],\n",
       " ['Afghanistan', 'AFG', '', '19', '1,380', '73'],\n",
       " ['West Indies', 'WI', '', '41', '2,902', '71'],\n",
       " ['Ireland', 'IRE', '', '23', '1,214', '53']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending request to the webpage server to get the source code \n",
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page\n",
    "#Getting the content from the page \n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "# scrapping the top 10 ODI teams in men's cricket  \n",
    "first_title=soup.find('tr',class_='table-body')\n",
    "first_title\n",
    "first_title.text\n",
    "teams =[]\n",
    "for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "    teams.append(i.text.split('\\n')[4:10])\n",
    "teams [0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78f29029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player Team Ratings\n",
       "0            Imam-ul-Haq  PAK     779\n",
       "1  Rassie van der Dussen   SA     766\n",
       "2        Quinton de Kock   SA     759\n",
       "3           David Warner  AUS     747\n",
       "4            Steve Smith  AUS     719\n",
       "5         Jonny Bairstow  ENG     710\n",
       "6            Virat Kohli  IND     707\n",
       "7           Rohit Sharma  IND     704\n",
       "8        Kane Williamson   NZ     701\n",
       "9         Josh Hazlewood  AUS     727"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batsmen_teams=BeautifulSoup(requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi').content,'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "player=[ i.text.strip() for i in batsmen_teams.find_all('td',class_='table-body__cell name')][:10] # Scrap player\n",
    "\n",
    "\n",
    "team=[ i.text for i in batsmen_teams.find_all('span',class_='table-body__logo-text')][:10] # Scrap Team \n",
    "\n",
    "rating=[i.text for i in batsmen_teams.find_all('td',class_='table-body__cell u-text-right rating')][:10] # Scrap Rating\n",
    "\n",
    "batsmen=pd.DataFrame({'Player':player,'Team':team,'Ratings':rating})\n",
    "\n",
    "batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "da09e7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Players</th>\n",
       "      <th>Teams</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[, Josh Hazlewood, ]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[, Mitchell Starc, ]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[, Shaheen Afridi, ]</td>\n",
       "      <td>PAK</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[, Matt Henry, ]</td>\n",
       "      <td>NZ</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[, Adam Zampa, ]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[, Mehedi Hasan, ]</td>\n",
       "      <td>BAN</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[, Mujeeb Ur Rahman, ]</td>\n",
       "      <td>AFG</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[, Mustafizur Rahman, ]</td>\n",
       "      <td>BAN</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[, Rashid Khan, ]</td>\n",
       "      <td>AFG</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[, Chris Woakes, ]</td>\n",
       "      <td>ENG</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Players Teams Ratings\n",
       "0     [, Josh Hazlewood, ]   AUS     727\n",
       "1     [, Mitchell Starc, ]   AUS     665\n",
       "2     [, Shaheen Afridi, ]   PAK     661\n",
       "3         [, Matt Henry, ]    NZ     656\n",
       "4         [, Adam Zampa, ]   AUS     655\n",
       "5       [, Mehedi Hasan, ]   BAN     655\n",
       "6   [, Mujeeb Ur Rahman, ]   AFG     650\n",
       "7  [, Mustafizur Rahman, ]   BAN     640\n",
       "8        [, Rashid Khan, ]   AFG     635\n",
       "9       [, Chris Woakes, ]   ENG     632"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending request to the webpage server to get the source code \n",
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "page\n",
    "\n",
    "#Getting the content from the page \n",
    "bowlers_team=BeautifulSoup(page.content)\n",
    "bowlers_team\n",
    "\n",
    "# scrapping the top 10 ODI bowlers \n",
    "players=[]\n",
    "for i in bowlers_team.find_all('td',class_='table-body__cell rankings-table__name name'):\n",
    "\n",
    "    players.append(i.text.split('\\n'))\n",
    "players[0:10]\n",
    "\n",
    "# scrapping the team \n",
    "teams=[]\n",
    "for i in bowlers_team.find_all('span',class_='table-body__logo-text'):\n",
    "\n",
    "    teams.append(i.text)\n",
    "teams[0:10]\n",
    "\n",
    "# scrapping the ratings \n",
    "ratings=[]\n",
    "for i in bowlers_team.find_all('td',class_='table-body__cell rating'):\n",
    "\n",
    "    ratings.append(i.text)\n",
    "ratings[0:10]\n",
    "\n",
    "# making the dataframe\n",
    "import pandas as pd\n",
    "bowlers=pd.DataFrame({'Players':players,'Teams':teams,'Ratings':ratings})\n",
    "bowlers[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5023371c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Match</th>\n",
       "      <th>Point</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>3,098</td>\n",
       "      <td>3,098</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>2,904</td>\n",
       "      <td>2,904</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>2,820</td>\n",
       "      <td>2,820</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>2,425</td>\n",
       "      <td>2,425</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>2,334</td>\n",
       "      <td>2,334</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team  Match  Point Rating\n",
       "0     Australia     26     26    119\n",
       "1  South Africa  3,098  3,098    116\n",
       "2       England     25     25    104\n",
       "3         India  2,904  2,904    101\n",
       "4   New Zealand     27     27     97\n",
       "5   West Indies  2,820  2,820     78\n",
       "6    Bangladesh     24     24     72\n",
       "7      Thailand  2,425  2,425     63\n",
       "8      Pakistan     24     24     44\n",
       "9     Sri Lanka  2,334  2,334     39"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending request to the webpage server to get the source code \n",
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "page\n",
    "#Getting the content from the page \n",
    "women_team=BeautifulSoup(page.content)\n",
    "women_team\n",
    "# scrap team\n",
    "team=[i.text.strip() for i in women_team.find_all('span',class_='u-hide-phablet')][:10]\n",
    "#scrap matches     \n",
    "match= [i.text for i in women_team.find_all('td',class_='table-body__cell u-center-text')][:10]\n",
    "points=[i.text for i in women_team.find_all('td',class_='table-body__cell u-center-text')][:10] # scrap points\n",
    "ratings=[i.text for i in women_team.find_all('td',class_='table-body__cell u-text-right rating')][:10] # scrap ratings\n",
    "     \n",
    "women_odi=pd.DataFrame({'Team':team,'Match':match,'Point':points,'Rating':ratings}) # making dataframe\n",
    "\n",
    "women_odi\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a6c228e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player Team Rating\n",
       "0          Beth Mooney  AUS    749\n",
       "1      Laura Wolvaardt   SA    732\n",
       "2       Natalie Sciver  ENG    725\n",
       "3     Harmanpreet Kaur  IND    716\n",
       "4      Smriti Mandhana  IND    714\n",
       "5          Meg Lanning  AUS    710\n",
       "6       Rachael Haynes  AUS    701\n",
       "7    Amy Satterthwaite   NZ    661\n",
       "8  Chamari Athapaththu   SL    655\n",
       "9         Ellyse Perry  AUS    642"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending request to the webpage server to get the source code \n",
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "page\n",
    "#Getting the content from the page \n",
    "women_team=BeautifulSoup(page.content)\n",
    "women_team\n",
    "# scrap team\n",
    "player=[i.text.strip() for i in women_team.find_all('td',class_='table-body__cell rankings-table__name name')][:10]\n",
    "team=[i.text for i in women_team.find_all('span',class_='table-body__logo-text')][:10]\n",
    "rating=[i.text for i in women_team.find_all('td',class_='table-body__cell rating')][:10]\n",
    "     \n",
    "Bating=pd.DataFrame({'Player':player,'Team':team,'Rating':rating})\n",
    "\n",
    "Bating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1d7ae90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>PAK</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team Rating\n",
       "0      Ellyse Perry  AUS    374\n",
       "1    Natalie Sciver  ENG    357\n",
       "2       Amelia Kerr   NZ    356\n",
       "3    Marizanne Kapp   SA    349\n",
       "4     Deepti Sharma  IND    322\n",
       "5  Ashleigh Gardner  AUS    270\n",
       "6     Jess Jonassen  AUS    246\n",
       "7    Jhulan Goswami  IND    214\n",
       "8   Katherine Brunt  ENG    207\n",
       "9          Nida Dar  PAK    205"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending request to the webpage server to get the source code \n",
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "page\n",
    "#Getting the content from the page \n",
    "women_team=BeautifulSoup(page.content)\n",
    "women_team\n",
    "# scrap team\n",
    "player=[i.text.strip() for i in women_team.find_all('td',class_='table-body__cell rankings-table__name name')][:10]\n",
    "team=[i.text for i in women_team.find_all('span',class_='table-body__logo-text')][:10]\n",
    "rating=[i.text for i in women_team.find_all('td',class_='table-body__cell rating')][:10]\n",
    "     \n",
    "All_rounders=pd.DataFrame({'Player':player,'Team':team,'Rating':rating})\n",
    "\n",
    "All_rounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a8763017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Headline, Time]\n",
       "Index: []"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://www.cnbc.com/search/?query=news&qsearchterm=news') # sending request\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)# getting content \n",
    "soup\n",
    "\n",
    "headline=[i.text.strip() for i in soup.find_all('span',class_='Card-title')] #scrap headline\n",
    "time=[i.text for i in soup.find_all('span',class_='SearchResult-publishedDate')] # scrap time\n",
    "news_link=[i.text for i in soup.find_all('a',class_='resultlink')]# scrap newslink\n",
    "\n",
    "df=pd.DataFrame({'Headline':headline,'Time':time,'Newslink':news_link})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e3a3d426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, BoÅ¡njak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social humanârobot in...</td>\n",
       "      <td>Lemaignan, SÃ©verin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, HernÃ¡ndez-Orallo, JosÃ© and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>BoÅ¡anskÃ½, Branislav, LisÃ½, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, LÃ¸land, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, TomÃ¡Å¡, BahnÃ­k, Å tÄpÃ¡n, FÃ¼rnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, GonÃ§alo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>âThat's (not) the output I expected!â On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social humanârobot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  âThat's (not) the output I expected!â On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Published date  \n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021  \n",
       "1           Evans, Richard, BoÅ¡njak, Matko and 5 more    October 2021  \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015  \n",
       "3                                 Boden, Margaret A.      August 1998  \n",
       "4     Lemaignan, SÃ©verin, Warnier, Mathieu and 3 more       June 2017  \n",
       "5                                        Miller, Tim    February 2019  \n",
       "6   Evans, Richard, HernÃ¡ndez-Orallo, JosÃ© and 3 more      April 2021  \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015  \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999  \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020  \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021  \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007  \n",
       "12       BoÅ¡anskÃ½, Branislav, LisÃ½, Viliam and 3 more     August 2016  \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021  \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997  \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021  \n",
       "16      Aas, Kjersti, Jullum, Martin, LÃ¸land, Anders   September 2021  \n",
       "17  Kliegr, TomÃ¡Å¡, BahnÃ­k, Å tÄpÃ¡n, FÃ¼rnkranz, Joha...       June 2021  \n",
       "18    Pereira, GonÃ§alo, Prada, Rui, Santos, Pedro A.    December 2016  \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021  \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021  \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014  \n",
       "22                      Kohavi, Ron, John, George H.    December 1997  \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021  \n",
       "24                                   Ying, Mingsheng    February 2010  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)# getting content \n",
    "soup\n",
    "titles=[i.text for i in soup.find_all('a',class_='sc-5smygv-0 fIXTHm')] #scrap paper titles\n",
    "authors=[i.text for i in soup.find_all('span',class_='sc-1w3fpd7-0 dnCnAO')] # scrap authors name\n",
    "dates=[i.text for i in soup.find_all('span',class_='sc-1thf9ly-2 dvggWt')]# scrap published date\n",
    "\n",
    "\n",
    "df1=pd.DataFrame({'Paper Title':titles,'Authors':authors,'Published date':dates})\n",
    "df1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4ea4fffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#skip-to-content-anchor\n",
      "http://www.elsevier.com\n",
      "https://account.elsevier.com/auth\n",
      "https://elsevier.com/about\n",
      "https://www.elsevier.com/connect\n",
      "https://www.elsevier.com/about/careers\n",
      "https://elsevier.com/about\n",
      "https://www.elsevier.com/connect\n",
      "https://www.elsevier.com/about/careers\n",
      "https://www.elsevier.com/rd-solutions\n",
      "https://www.elsevier.com/clinical-solutions\n",
      "https://www.elsevier.com/research-platforms\n",
      "https://www.elsevier.com/research-intelligence\n",
      "https://www.elsevier.com/education\n",
      "https://www.elsevier.com/solutions\n",
      "https://www.elsevier.com/rd-solutions\n",
      "https://www.elsevier.com/clinical-solutions\n",
      "https://www.elsevier.com/research-platforms\n",
      "https://www.elsevier.com/research-intelligence\n",
      "https://www.elsevier.com/education\n",
      "https://www.elsevier.com/solutions\n",
      "https://www.elsevier.com/authors\n",
      "https://www.elsevier.com/editors\n",
      "https://www.elsevier.com/reviewers\n",
      "https://www.elsevier.com/librarians\n",
      "https://www.elsevier.com/strategic-partners\n",
      "https://www.elsevier.com/open-access\n",
      "https://www.elsevier.com/societies\n",
      "https://www.elsevier.com/authors\n",
      "https://www.elsevier.com/editors\n",
      "https://www.elsevier.com/reviewers\n",
      "https://www.elsevier.com/librarians\n",
      "https://www.elsevier.com/strategic-partners\n",
      "https://www.elsevier.com/open-access\n",
      "https://www.elsevier.com/societies\n",
      "https://www.elsevier.com/books-and-journals\n",
      "https://webshop.elsevier.com/?utm_source=ecom&utm_medium=top&utm_campaign=webshop\n",
      "https://www.elsevier.com/books-and-journals\n",
      "https://webshop.elsevier.com/?utm_source=ecom&utm_medium=top&utm_campaign=webshop\n",
      "https://global-checkout.elsevier.com\n",
      "https://account.elsevier.com/auth\n",
      "https://www.sciencedirect.com/science/journal/00043702\n",
      "https://www.editorialmanager.com/artint/default.aspx\n",
      "https://www.elsevier.com/\n",
      "https://www.elsevier.com/search-results?labels=journals\n",
      "/artificial-intelligence\n",
      "/artificial-intelligence/most-downloaded-articles\n",
      "https://www.sciencedirect.com/science/journal/00043702\n",
      "https://www.editorialmanager.com/artint/default.aspx\n",
      "https://www.sciencedirect.com/science/journal/00043702\n",
      "https://www.elsevier.com/journals/artificial-intelligence/0004-3702/guide-for-authors\n",
      "https://www.editorialmanager.com/artint/default.aspx\n",
      "https://authors.elsevier.com/tracking/landingpage/selection.do\n",
      "https://www.elsevier.com/journals/artificial-intelligence/0004-3702/subscribe?subscriptiontype=institutional\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370221000862\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370221000722\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370215000910\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370298000551\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370216300790\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370218305988\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370220301855\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370214001386\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370299000521\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370219300116\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370220301533\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370207000793\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370216300285\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370220301958\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370297000635\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370221000515\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370221000539\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370221000096\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370216300868\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370221000588\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370221000102\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370213001082\n",
      "https://www.sciencedirect.com/science/article/pii/S000437029700043X\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370221000734\n",
      "https://www.sciencedirect.com/science/article/pii/S0004370209001398\n",
      "https://www.sciencedirect.com/science/journal/00043702\n",
      "https://www.sciencedirect.com/user/alerts\n",
      "https://www.sciencedirect.com/user/register?utm_campaign=sd_recommender_ELSJLS&utm_channel=elseco&dgcid=sd_recommender_ELSJLS\n",
      "http://www.elsevier.com/authors/home\n",
      "https://www.editorialmanager.com/artint/default.aspx\n",
      "https://www.editorialmanager.com/artint/default.aspx\n",
      "https://researcheracademy.elsevier.com\n",
      "https://www.elsevier.com/about/policies/copyright/permissions\n",
      "https://webshop.elsevier.com\n",
      "https://service.elsevier.com/app/home/supporthub/publishing/#authors\n",
      "https://authors.elsevier.com/tracking/landingpage/selection.do\n",
      "https://www.elsevier.com/librarians\n",
      "https://www.elsevier.com/journals/artificial-intelligence/0004-3702/subscribe?subscriptiontype=institutional\n",
      "http://www.elsevier.com/editors\n",
      "http://www.elsevier.com/editors/perk\n",
      "https://www.elsevier.com/editors/guest-editors\n",
      "https://service.elsevier.com/app/home/supporthub/publishing/#editors\n",
      "http://www.elsevier.com/reviewers\n",
      "https://www.elsevier.com/reviewers/how-to-review\n",
      "https://www.editorialmanager.com/artint/default.aspx\n",
      "https://www.elsevier.com/reviewers/becoming-a-reviewer-how-and-why#recognizing\n",
      "https://service.elsevier.com/app/home/supporthub/publishing/#reviewers\n",
      "https://www.elsevier.com\n",
      "//www.elsevier.com/legal/elsevier-website-terms-and-conditions\n",
      "//www.elsevier.com/legal/privacy-policy\n",
      "//www.elsevier.com/legal/cookienotice\n",
      "//www.elsevier.com/sitemap\n",
      "https://www.relx.com/\n"
     ]
    }
   ],
   "source": [
    "url=[] # scrap paper urls\n",
    "for i in soup.find_all('a'):\n",
    "    print(i.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6903d7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Names</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>â¹ 2,000 for 2 (approx) | Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>â¹ 1,680 for 2 (approx) | North Indian, Asian, ...</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>â¹ 2,000 for 2 (approx) | Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>â¹ 3,000 for 2 (approx) | Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>â¹ 1,700 for 2 (approx) | North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>â¹ 2,400 for 2 (approx) | North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>â¹ 1,800 for 2 (approx) | North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>â¹ 1,900 for 2 (approx) | North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>â¹ 2,200 for 2 (approx) | North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Restaurant Names  \\\n",
       "0                   Castle Barbeque   \n",
       "1                   Jungle Jamboree   \n",
       "2                   Castle Barbeque   \n",
       "3                        Cafe Knosh   \n",
       "4              The Barbeque Company   \n",
       "5                       India Grill   \n",
       "6                    Delhi Barbeque   \n",
       "7  The Monarch - Bar Be Que Village   \n",
       "8                 Indian Grill Room   \n",
       "\n",
       "                                             Cuisine  \\\n",
       "0     â¹ 2,000 for 2 (approx) | Chinese, North Indian   \n",
       "1  â¹ 1,680 for 2 (approx) | North Indian, Asian, ...   \n",
       "2     â¹ 2,000 for 2 (approx) | Chinese, North Indian   \n",
       "3      â¹ 3,000 for 2 (approx) | Italian, Continental   \n",
       "4     â¹ 1,700 for 2 (approx) | North Indian, Chinese   \n",
       "5     â¹ 2,400 for 2 (approx) | North Indian, Italian   \n",
       "6              â¹ 1,800 for 2 (approx) | North Indian   \n",
       "7              â¹ 1,900 for 2 (approx) | North Indian   \n",
       "8     â¹ 2,200 for 2 (approx) | North Indian, Mughlai   \n",
       "\n",
       "                                            Location Ratings  \\\n",
       "0                     Connaught Place, Central Delhi     4.1   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "2             Pacific Mall,Tagore Garden, West Delhi     3.9   \n",
       "3  The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "4                 Gardens Galleria,Sector 38A, Noida       4   \n",
       "5               Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi     3.6   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "\n",
       "                                           Image URL  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending request to the webpage server to get the source code \n",
    "page=requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page\n",
    "#Getting the content from the page \n",
    "rst=BeautifulSoup(page.content)\n",
    "rst\n",
    "# scrap team\n",
    "Restaurant=[i.text.strip() for i in rst.find_all('a',class_='restnt-name ellipsis')]\n",
    "Cuisine=[i.text for i in rst.find_all('span',class_='double-line-ellipsis')]\n",
    "Location=[i.text for i in rst.find_all('div',class_='restnt-loc ellipsis')]\n",
    "Rating=[i.text for i in rst.find_all('div',class_='restnt-rating rating-4')]\n",
    "Image_url=[i.get('data-src') for i in rst.find_all('img',class_='no-img')]\n",
    "\n",
    "           \n",
    "restaurant=pd.DataFrame({'Restaurant Names':Restaurant,'Cuisine':Cuisine,'Location':Location,'Ratings':Rating,'Image URL': Image_url})\n",
    "restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ca8fe4c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [154]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m h5_index\u001b[38;5;241m=\u001b[39m[i\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m'\u001b[39m,class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_mvt_n\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     10\u001b[0m h5_median\u001b[38;5;241m=\u001b[39m[i\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m,class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs_ibl gsc_mp_anchor\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m---> 12\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRank\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPublication\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mpublication\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mH5 Index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mh5_index\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mH5 Median\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mh5_median\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m df\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "page=requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en') # sending request\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)# getting content \n",
    "soup\n",
    "\n",
    "rank=[i.text.strip() for i in soup.find_all('td',class_='gsc_mvt_p')] \n",
    "publication=[i.text for i in soup.find_all('td',class_='gsc_mvt_t')] \n",
    "h5_index=[i.text for i in soup.find_all('td',class_='gsc_mvt_n')]\n",
    "h5_median=[i.text for i in soup.find_all('span',class_='gs_ibl gsc_mp_anchor')]\n",
    "\n",
    "df=pd.DataFrame({'Rank':rank,'Publication':publication,'H5 Index':h5_index,'H5 Median':h5_median})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3e4d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
